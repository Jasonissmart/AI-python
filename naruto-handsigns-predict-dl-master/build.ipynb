{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火影忍者結印影像辨識\n",
    "\n",
    "### 組員:\n",
    "財管四 105307030 陳韋勳<br>\n",
    "應數一 108701016 洪晨維<br>\n",
    "應數一 108701044 戴煜偉<br>\n",
    "應數一 108701003 林均宥\n",
    "\n",
    "## 1. 動機\n",
    "如果想要成為一名強大的火影，修練S級忍術的結印是一條必經之路，更是我們這組成員的最終目標！<br>\n",
    "然而問題出現了，我們知道了訓練的方法，卻沒有驗證結印正確性的工具。<br>\n",
    "因此，我們這組希望能夠透過機器學習來判斷我們比出的結印的正確性。<br>\n",
    "\n",
    "\n",
    "## 2. 參考程式碼及資料集來源\n",
    "https://github.com/angry-coder-room/naruto-handsigns-predict-dl<br>\n",
    "已徵求到作者程式碼以及圖片使用的授權!\n",
    "經剔除不合適的照片後，剩7799張，將其中6214張分成train檔，剩下1585張分成test檔<br>\n",
    "GoogLeNet模型程式碼參考來源:https://blog.csdn.net/qq_25491201/article/details/78367696?fbclid=IwAR0SD-Bfzymq1SMe-nzcIYBtwlPNh935zLrSYdI41VdGdpnFEnk9WBtOfZk\n",
    "\n",
    "## 3. 模型選擇\n",
    " 作者原本採用的模型是LeNet-5模型搭配AlexNet模型中避免overfitting的兩個方法: Data Augmentation & dropout，<br>\n",
    "但因為作者的模型在測試資料檔中的準確率並不高，於是我們研究了幾個比較有名的CNN模型，<br>其中包括: LeNet, AlexNet, VGGNet以及GoogLeNet。<br>最後我們決定採用用GoogLeNet模型並搭配一些AlexNet模型中避免overfitting的方法\n",
    "#### 我們從LeNet、AlexNet、VGGNet及GoogLeNet中挑選出GoogLeNet主要有兩個原因:<br><br> 1. 因為其結合了其他三者的長處並提出Inception這種創新的網路結構。<br><br>2. GoogLeNet在2014年ImageNet挑戰賽(ILSVRC14)獲得第一名\n",
    "\n",
    "## 分工:\n",
    "### 陳韋勳: 資料處理、建構模型、報告撰寫\n",
    "### 洪晨維: 資料處理、建構模型\n",
    "### 戴煜偉: 資料處理、建構模型、比較模型、報告撰寫\n",
    "### 林均宥: 建構模型、圖像化預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.metrics as metric\n",
    "from keras import backend as K\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6214 images belonging to 8 classes.\n",
      "Found 6214 images belonging to 8 classes.\n",
      "Found 1585 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "NB_CLASS=9\n",
    "LEARNING_RATE=0.01\n",
    "MOMENTUM=0.9\n",
    "DROPOUT=0.4\n",
    "WEIGHT_DECAY=0.0005\n",
    "LRN2D_NORM=True\n",
    "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
    "USE_BN=True\n",
    "\n",
    "train_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
    "vaildation_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
    "test_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTest'\n",
    "\n",
    "IM_WIDTH=114\n",
    "IM_HEIGHT=114\n",
    "batch_size=400\n",
    "EPOCH= 25\n",
    "\n",
    "#train data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#vaild data\n",
    "vaild_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "vaild_generator = train_datagen.flow_from_directory(\n",
    "  vaildation_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "  test_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#normalization\n",
    "def conv2D_lrn2d(x,filters,kernel_size,strides=(1,1),padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=WEIGHT_DECAY):\n",
    "    #l2 normalization\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "\n",
    "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    if lrn2d_norm:\n",
    "        #batch normalization\n",
    "        x=BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_module(x,params,concat_axis,padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=None):\n",
    "    (branch1,branch2,branch3,branch4)=params\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "    #1x1\n",
    "    pathway1=Conv2D(filters=branch1[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    #1x1->3x3\n",
    "    pathway2=Conv2D(filters=branch2[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway2=Conv2D(filters=branch2[1],kernel_size=(3,3),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway2)\n",
    "\n",
    "    #1x1->5x5\n",
    "    pathway3=Conv2D(filters=branch3[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway3=Conv2D(filters=branch3[1],kernel_size=(5,5),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway3)\n",
    "\n",
    "    #3x3->1x1\n",
    "    pathway4=MaxPooling2D(pool_size=(3,3),strides=1,padding=padding,data_format=DATA_FORMAT)(x)\n",
    "    pathway4=Conv2D(filters=branch4[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway4)\n",
    "\n",
    "    return concatenate([pathway1,pathway2,pathway3,pathway4],axis=concat_axis)\n",
    "\n",
    "def create_model():\n",
    "    #Data format:tensorflow,channels_last;theano,channels_last\n",
    "    if DATA_FORMAT=='channels_first':\n",
    "        INP_SHAPE=(3,114,114)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=1\n",
    "    elif DATA_FORMAT=='channels_last':\n",
    "        INP_SHAPE=(114,114,3)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=3\n",
    "    else:\n",
    "        raise Exception('Invalid Dim Ordering')\n",
    "\n",
    "    x=conv2D_lrn2d(img_input,64,(5,5),2,padding='same',lrn2d_norm=False)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "\n",
    "    x=conv2D_lrn2d(x,64,(1,1),1,padding='same',lrn2d_norm=False)\n",
    "\n",
    "    x=conv2D_lrn2d(x,192,(3,3),1,padding='same',lrn2d_norm=True)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(64,),(96,128),(16,32),(32,)],concat_axis=CONCAT_AXIS) #3a\n",
    "    x=inception_module(x,params=[(128,),(128,192),(32,96),(64,)],concat_axis=CONCAT_AXIS) #3b\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    \n",
    "    ### 為了讓訓練的速度增加 將兩層數收起來\n",
    "    \n",
    "    #x=inception_module(x,params=[(192,),(96,208),(16,48),(64,)],concat_axis=CONCAT_AXIS) #4a\n",
    "    #x=inception_module(x,params=[(160,),(112,224),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4b\n",
    "    #x=inception_module(x,params=[(128,),(128,256),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4c\n",
    "    #x=inception_module(x,params=[(112,),(144,288),(32,64),(64,)],concat_axis=CONCAT_AXIS) #4d\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #4e\n",
    "    #x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #5a\n",
    "    #x=inception_module(x,params=[(384,),(192,384),(48,128),(128,)],concat_axis=CONCAT_AXIS) #5b\n",
    "    #x=AveragePooling2D(pool_size=(7,7),strides=1,padding='valid',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dropout(DROPOUT)(x)\n",
    "    x=Dense(NB_CLASS,activation='linear')(x)\n",
    "    x=Dense(NB_CLASS,activation='softmax')(x)\n",
    "\n",
    "    return x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create the Model\n",
    "    x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT=create_model()\n",
    "\n",
    "    # Create a Keras Model\n",
    "    model=Model(inputs=img_input,outputs=[x])\n",
    "    model.summary()\n",
    "\n",
    "    # Save a PNG of the Model Build\n",
    "    # plot_model(model,to_file='GoogLeNet.png',show_shapes=True)\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc',metric.top_k_categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "if __name__=='__main__':\n",
    "    if os.path.exists('inception_1.h5'):\n",
    "        model=load_model('inception_1.h5')\n",
    "    else:\n",
    "        model=check_print()\n",
    "\n",
    "    model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "                        ,validation_steps=vaild_generator.n/batch_size)\n",
    "    model.save('inception_1.h5')\n",
    "    model.metrics=['acc',metric.top_k_categorical_accuracy]\n",
    "    loss,acc,top_acc=model.evaluate_generator(test_generator,steps=test_generator.n/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用pygame模組，對即時結印影像做判斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import cv2\n",
    "import sys, os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "from PIL import Image\n",
    "import pygame\n",
    "\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((900,900),pygame.RESIZABLE)\n",
    "\n",
    "CLIP_X1 = 160\n",
    "CLIP_Y1 = 140\n",
    "CLIP_X2 = 400\n",
    "CLIP_Y2 = 360\n",
    "\n",
    "with open('model_in_json.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "loaded_model = model_from_json(model_json)\n",
    "loaded_model.load_weights('model_weights.h5')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, FrameImage = cap.read()\n",
    "    FrameImage = cv2.flip(FrameImage, 1)\n",
    "    cv2.imshow(\"\", FrameImage)\n",
    "    cv2.rectangle(FrameImage, (CLIP_X1, CLIP_Y1), (CLIP_X2, CLIP_Y2), (0,255,0) ,1)\n",
    "\n",
    "    ROI = FrameImage[CLIP_Y1:CLIP_Y2, CLIP_X1:CLIP_X2]\n",
    "    ROI = cv2.resize(ROI, (64, 64)) \n",
    "    ROI = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
    "    #ROI= cv2.add(ROI,np.array([40.0]))\n",
    "    _, output = cv2.threshold(ROI, 100, 255, cv2.THRESH_BINARY) # adjust brightness\n",
    "    \n",
    "    SHOWROI = cv2.resize(ROI, (256, 256)) \n",
    "    _, output2 = cv2.threshold(SHOWROI, 100, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"ROI\", output2)\n",
    "    \n",
    "    result = loaded_model.predict(output.reshape(1, 64, 64, 1))\n",
    "    predict =   { 'bird':    result[0][0],\n",
    "                  'dragon':    result[0][1],    \n",
    "                  'horse':    result[0][2],\n",
    "                  'monkey':    result[0][3],\n",
    "                  'dog':    result[0][3],\n",
    "                  'ox':    result[0][5],\n",
    "                  'serpent':    result[0][6],\n",
    "                  'ram':    result[0][7],\n",
    "                  }\n",
    "    \n",
    "    predict = sorted(predict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    if(predict[0][1] == 1.0):\n",
    "        predict_img  = pygame.image.load(os.getcwd() + '/images/' + predict[0][0] + '.png')\n",
    "    else:\n",
    "        predict_img  = pygame.image.load(os.getcwd() + '/images/nosign.png')\n",
    "    predict_img = pygame.transform.scale(predict_img, (900, 900))\n",
    "    screen.blit(predict_img, (0,0))\n",
    "    pygame.display.flip()\n",
    "    interrupt = cv2.waitKey(10)\n",
    "\n",
    "    if interrupt & 0xFF == ord('q'): # esc key\n",
    "        break\n",
    "            \n",
    "pygame.quit()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
